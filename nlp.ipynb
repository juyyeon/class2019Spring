{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* s에서 t로 가려면 split쓰면 쪼개진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nltk.Text(t)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nltk에 포함된 text라는 함수를 씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: a man in the house...>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.Text(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\오주연\\\\hsnam/06_01.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-44bfbd4ac9e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34mr'/06_01.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\오주연\\\\hsnam/06_01.txt'"
     ]
    }
   ],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os에서 현재 디렉토리를 받아오는 함수 + 현재 디렉토리에 포함되어 있는 6_01이라는 파일 full path. 즉 디렉토리부터 파일링까지 포함한 full path. 파일을 열어라.\n",
    "\n",
    "* 텍스트는 다양한 인코딩이 있는데, utf8로 인코딩 되어 있음. (다른 것으로 되어 있으면 다른 것으로 변경해야 함)\n",
    "\n",
    "* .read()를 하면 불러옴.\n",
    "\n",
    "* 디렉토리 안에 있는 텍스트 파일을 불러오게 되고, raw에 그 텍스트가 들어와 있음.\n",
    "\n",
    "* raw, print(raw)라고 하면 텍스트 파일이 나옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1154507\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* type, len(길이) 알아보기\n",
    "\n",
    "* 제일 처음부터 75번째까지."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* split : 단어끼리 잘라주는 것\n",
    "\n",
    "* tokenize : raw str을 넣으면 token으로.\n",
    "\n",
    "* tokens으로 받아진 variable type은 list로 받아짐 (split과 결과 동일)\n",
    "\n",
    "* len : 글자수와 비슷\n",
    "\n",
    "* 각각의 잘라진 token word를 보자. 10번째까지.\n",
    "\n",
    "--> title, :, crime, and, punishment, author...\n",
    "\n",
    "--> 단어만 뽑아내려고 할 때 word tokenize. nltk라는 library 안에 포함되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "text.collocations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Text 함수\n",
    "\n",
    "* text type : nltk 전용 variable로 만들어졌다.\n",
    "\n",
    "* 10번째 까지 보면 ...만들어져있다\n",
    "\n",
    "* 왜 nltk 전용 variable을 만드는 것이 좋은가? nltk에 있는 다양한 함수를 쓸 수 있다.\n",
    "\n",
    "* text.collocations() 는 같이 나올 확률이 큰 것끼리 묶어줌.\n",
    "\n",
    "--> 대부분 이름과 성... 자주 나오는 corlocation이다. // 소설이 아니라면 자주 나오는 숙어 등..\n",
    "\n",
    "--> young man도 자주 발견."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 162 matches:\n",
      "and were more frequent in periods of great strain . In 1859 he was allowed to r\n",
      "ndency and of late she had read with great interest a book she got through Mr. \n",
      " the bosom of her family ... . And a great deal more ... . Quite excusable , si\n",
      "that you had heard that Dounia had a great deal to put up with in the Svidrigra\n",
      "g will she has . Dounia can endure a great deal and even in the most difficult \n",
      " that letter she reproached him with great heat and indignation for the basenes\n",
      "putation ; they had seen and known a great deal more than Mr. Svidrigailov had \n",
      "n other people ’ s . In my opinion a great deal , a very great deal of all this\n",
      " In my opinion a great deal , a very great deal of all this was unnecessary ; b\n",
      " . He is a very busy man and is in a great hurry to get to Petersburg , so that\n",
      " me that , though he is not a man of great education , he is clever and seems t\n",
      " very well . Of course , there is no great love either on his side , or on hers\n",
      "tted the matter has been arranged in great haste . Besides he is a man of great\n",
      "great haste . Besides he is a man of great prudence and he will see , to be sur\n",
      "d that she is ready to put up with a great deal , if only their future relation\n",
      " off for Petersburg , where he has a great deal of business , and he wants to o\n",
      "a or I breathed a word to him of the great hopes we have of his helping us to p\n",
      "ites that ‘ Dounia can put up with a great deal. ’ I know that very well . I kn\n",
      "at , that ‘ Dounia can put up with a great deal. ’ If she could put up with Mr.\n",
      "it , she certainly can put up with a great deal . And now mother and she have t\n",
      "e young , and she was walking in the great heat bareheaded and with no parasol \n",
      "f the skirt , close to the waist : a great piece was rent and hanging loose . A\n",
      "ts or conversations . He worked with great intensity without sparing himself , \n",
      " uproarious and was reputed to be of great physical strength . One night , when\n",
      ". His legs felt suddenly heavy and a great drowsiness came upon him . He turned\n"
     ]
    }
   ],
   "source": [
    "text.concordance('great', 79, 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 쓰는 방법은 text.concordance('great', 79, 25) \n",
    "\n",
    "* text 속에서 great가 보이는 모든 것을 spotting 하는데 문맥을 보고 싶은 것. great를 중심으로 양쪽으로 총 79개 character를 보면 어떤 문맥에서 쓰이는 지 알 수 있음. 너무 길다면 79 숫자 바꾸면 됨.\n",
    "\n",
    "* 처음부터 25번째까지 나오는 sample을 뽑아오는 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 198098), ('e', 115855), ('t', 85539), ('a', 75266), ('o', 68338)]\n",
      "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'a', 'o', 'n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "fdist = nltk.FreqDist(raw)\n",
    "print(fdist.most_common(5))\n",
    "\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(fdist.most_common(5))\n",
    "[char for (char, count) in fdist.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nltk라는 library : library는 함수뿐만 아니라 그냥 데이터를 갖다 놓기도 함. 예제 데이터 등을 갖다 놓을 수 있다. nltk가 아나콘다 깔면서 깔린 것인데, melvile이라는 mobydic 사전 등 다양하게 있음. \n",
    "\n",
    "* fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha()) \n",
    "    --> 앞에서 200번째까지 스트링 나올 것임.\n",
    "    \n",
    "* print(fdist.most_common(5)) 가장 자주 나온 것 찾기.\n",
    "\n",
    "* 제일 common한 것 ' '\n",
    "\n",
    "* 철자 중에서 어떤 것이 가장 빈번하게 나왔나? \n",
    "\n",
    "* ctrl+/ --> command \n",
    "\n",
    "* (ch.lower() for ch in raw if ch.isalpha()) : raw = txt 속에서 100만번 루프를 도는데, ch가 들어가는게 for loop에 if가 들어갔을 때 알파벳이냐?라고 질문. 알파벳이면 그것을 리스트로 만드는데, list로 만들어라. 그 속에 있는 캐릭터를 모두 담아 오는데, 숫자나 문장부호빼고 대문자는 소문자화시켜서 이 모든 것에 포함시키기겠다. 이 과정이 지나면 캐릭터가 100만개 들어있으면 list는 100만개가 생긴다. 그것이 들어가는데...\n",
    "\n",
    "* fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha()) 하면.\n",
    "    --> 아까는 문장 부호 포함되어 있었는데, 여기선 소문자만 문장부호 없이 도출된다. 어떤 철자가 영어에서 e가 제일 많이 나오는구나. 전반적으로 모음에 해당되는 철자가 더 많이 나온다는 것을 알 수 있음.\n",
    "    \n",
    "* [char for (char, count) in fdist.most_common(5)] : tuple이라고 해서 두 개의 정보가 들어옴. in 다음에 단순한 list가 있으면 단순한데 .. for loop가 두 개의 loop를 가져옴. character 와 count를 가지고 돈다. 5번 돈다 (시험) . 5번 도는데 character만 받아라. 두개를 가지고 총 다섯번의 loop를 돌면서 캐릭터가 바뀐다......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zymosis',\n",
       " 'zymosterol',\n",
       " 'zymosthenic',\n",
       " 'zymotechnic',\n",
       " 'zymotechnical',\n",
       " 'zymotechnics',\n",
       " 'zymotechny',\n",
       " 'zymotic',\n",
       " 'zymotically',\n",
       " 'zymotize',\n",
       " 'zymotoxic',\n",
       " 'zymurgy',\n",
       " 'Zyrenian',\n",
       " 'Zyrian',\n",
       " 'Zyryan',\n",
       " 'zythem',\n",
       " 'Zythia',\n",
       " 'zythum',\n",
       " 'Zyzomys']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
